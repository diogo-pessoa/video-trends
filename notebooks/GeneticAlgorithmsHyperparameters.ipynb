{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_data = pd.read_csv('combined_data.csv').set_index('video_id')\n",
    "label = combined_data['label']\n",
    "features = combined_data.drop(['label'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T13:41:13.818136Z",
     "start_time": "2024-02-17T13:41:13.258569Z"
    }
   },
   "id": "b985b31831eab822",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-15T20:32:07.349252Z",
     "start_time": "2024-02-15T20:32:07.226071Z"
    }
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# # Initialize the regression model\n",
    "# model = LogisticRegression(random_state=42, penalty='l1', solver='liblinear')\n",
    "# \n",
    "# # 1. Initial Population\n",
    "# def initialise_population(size, n_feat):\n",
    "#     population = []\n",
    "#     for _ in range(size):\n",
    "#         chromosome = np.ones(n_feat, dtype=bool)\n",
    "#         chromosome[:int(0.3 * n_feat)] = False\n",
    "#         np.random.shuffle(chromosome)\n",
    "#         population.append(chromosome)\n",
    "#     return population\n",
    "# \n",
    "# # 2. Fitness Function\n",
    "# def fitness_score(population, X_train, X_test, y_train, y_test):\n",
    "#     scores = []\n",
    "#     for chromosome in population:\n",
    "#         X_train_filtered = X_train[:, chromosome]\n",
    "#         X_test_filtered = X_test[:, chromosome]\n",
    "#         model.fit(X_train_filtered, y_train)\n",
    "#         predictions = model.predict(X_test_filtered)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         # Use negative MSE because we want to maximize fitness (minimize MSE)\n",
    "#         scores.append(-mse)\n",
    "#     scores, population = np.array(scores), np.array(population)\n",
    "#     inds = np.argsort(scores)[::-1]  # Sort so that individuals with higher scores (lower MSE) come first\n",
    "#     return list(scores[inds]), list(population[inds])\n",
    "# \n",
    "# # 3. Selection\n",
    "# def selection(pop_after_fit, n_parents):\n",
    "#     return pop_after_fit[:n_parents]\n",
    "# \n",
    "# # 4. Crossover\n",
    "# def crossover(pop_after_sel):\n",
    "#     population_nextgen = []\n",
    "#     for i in range(0, len(pop_after_sel)-1, 2):\n",
    "#         child1, child2 = pop_after_sel[i].copy(), pop_after_sel[i+1].copy()\n",
    "#         crossover_point = np.random.randint(1, len(child1)-1)\n",
    "#         child1[crossover_point:], child2[crossover_point:] = child2[crossover_point:], child1[crossover_point:]\n",
    "#         population_nextgen.extend([child1, child2])\n",
    "#     return population_nextgen\n",
    "# \n",
    "# # 5. Mutation\n",
    "# def mutation(pop_after_cross, mutation_rate):\n",
    "#     population_nextgen = []\n",
    "#     for chromosome in pop_after_cross:\n",
    "#         chromosome = np.array([not gene if random.random() < mutation_rate else gene for gene in chromosome])\n",
    "#         population_nextgen.append(chromosome)\n",
    "#     return population_nextgen\n",
    "# \n",
    "# # Generations\n",
    "# def generations(size, n_feat, n_parents, mutation_rate, n_gen, X_train, X_test, y_train, y_test):\n",
    "#     best_chromo = []\n",
    "#     best_score = []\n",
    "#     population_nextgen = initialise_population(size, n_feat)\n",
    "#     for _ in range(n_gen):\n",
    "#         scores, pop_after_fit = fitness_score(population_nextgen, X_train, X_test, y_train, y_test)\n",
    "#         pop_after_sel = selection(pop_after_fit, n_parents)\n",
    "#         pop_after_cross = crossover(pop_after_sel)\n",
    "#         population_nextgen = mutation(pop_after_cross, mutation_rate)\n",
    "#         best_chromo.append(pop_after_fit[0])\n",
    "#         best_score.append(scores[0])\n",
    "#     return best_chromo, best_score\n",
    "# size = 50  # Population size\n",
    "# n_feat = x_train.shape[1]  # Number of features\n",
    "# n_parents = 25  # Number of parents for crossover\n",
    "# mutation_rate = 0.01  # Mutation rate\n",
    "# n_gen = 100  # Number of generations\n",
    "# \n",
    "# # Record the start time\n",
    "# start_time = time.time()\n",
    "# best_chromo, best_score = generations(size, n_feat, n_parents, mutation_rate, n_gen, x_train, x_test, y_train, y_test)\n",
    "# # Calculate the duration\n",
    "# end_time = time.time()\n",
    "# duration = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\"\"\"\n",
    "X,Y - Training Data: Features and Label\n",
    "x_test, y_test - Testing Data: Features and Label\n",
    "\"\"\"\n",
    "X, x_test, y, y_test = train_test_split(features.values, label.values, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T13:46:58.902022Z",
     "start_time": "2024-02-17T13:46:58.157087Z"
    }
   },
   "id": "9a963d57fa08a045",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://deap.readthedocs.io/en/master/index.html\n",
    "# https://deap.readthedocs.io/en/master/tutorials/basic/part1.html\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beb2f64a13a26a2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deap\r\n",
      "  Downloading deap-1.4.1-cp39-cp39-macosx_11_0_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy in /Users/diogo.pessoa/code/video-trends/venv/lib/python3.9/site-packages (from deap) (1.26.3)\r\n",
      "Downloading deap-1.4.1-cp39-cp39-macosx_11_0_x86_64.whl (104 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m104.7/104.7 kB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: deap\r\n",
      "Successfully installed deap-1.4.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install deap"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T13:38:31.879503Z",
     "start_time": "2024-02-17T13:38:28.461256Z"
    }
   },
   "id": "fe0b852595a3b958",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diogo.pessoa/code/video-trends/venv/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t50    \n",
      "1  \t30    \n",
      "2  \t36    \n",
      "3  \t31    \n",
      "4  \t31    \n",
      "5  \t31    \n",
      "6  \t30    \n",
      "7  \t21    \n",
      "8  \t26    \n",
      "9  \t28    \n",
      "10 \t27    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from deap import base, creator, tools, algorithms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define problem to DEAP (we aim to minimize RMSE, hence weights=(-1.0,))\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "                 toolbox.attr_bool, n=X.shape[1])\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Define the fitness function for regression\n",
    "def evalModel(individual):\n",
    "    X_selected = X[:, [i for i, bit in enumerate(individual) if bit == 1]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if X_train.shape[1] == 0:  # Prevent training with 0 features\n",
    "        return (float(\"inf\"),)  # Return infinite RMSE as a penalty\n",
    "\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, predictions))  # Calculate RMSE\n",
    "    return (rmse,)\n",
    "\n",
    "toolbox.register(\"evaluate\", evalModel)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Parameters for GA\n",
    "population_size = 50\n",
    "crossover_probability = 0.5\n",
    "mutation_probability = 0.2\n",
    "number_of_generations = 40\n",
    "\n",
    "pop = toolbox.population(n=population_size)\n",
    "\n",
    "# Run the Genetic Algorithm\n",
    "result = algorithms.eaSimple(pop, toolbox, cxpb=crossover_probability,\n",
    "                             mutpb=mutation_probability, ngen=number_of_generations,\n",
    "                             verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-17T13:47:05.067205Z"
    }
   },
   "id": "278722f3a5d381d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"Best Score:\", best_score[-1])\n",
    "# mse = mean_squared_error(y_test, gbr_pred)\n",
    "# r_two_score = r2_score(y_test, gbr_pred)\n",
    "# ex_variance_score = explained_variance_score(y_test, gbr_pred)\n",
    "\n",
    "print(f\"GA algorithm  took {duration:.2f} seconds.\")\n",
    "# print(f'Mean Squared Error on Test Set: {mse}')\n",
    "# print(f'r2 score: {r_two_score}')\n",
    "# print(f'explained variance score: {ex_variance_score}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "840f4f0ca43f2347"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "x_train_genetic = x_train[:, best_chromo[-1]]\n",
    "x_test_genetic = x_test[:, best_chromo[-1]]\n",
    "n_estimators=140\n",
    "# Training classifiers\n",
    "grad_boosting_regressor.fit(x_train_genetic, y_train)\n",
    "ada_boosting_regressor.fit(x_train_genetic, y_train)\n",
    "bagging_regressor.fit(x_train_genetic, y_train)\n",
    "random_forest_regressor.fit(x_train_genetic, y_train)\n",
    "linear_regr.fit(x_train_genetic, y_train)\n",
    "voting_reg.fit(x_train_genetic, y_train) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b861c3887ba8aae5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "print('mean squared error', 'r2 score', 'explained variance score')\n",
    "print('GradientBoostingRegressor',mean_squared_error(y_test, gdb_prediction),r2_score(y_test, gdb_prediction), explained_variance_score(y_test, gdb_prediction))\n",
    "print('RandomForestRegressor',mean_squared_error(y_test, rf_prediction),r2_score(y_test, rf_prediction), explained_variance_score(y_test, rf_prediction))\n",
    "print('LinearRegression',mean_squared_error(y_test, lg_prediction),r2_score(y_test, lg_prediction), explained_variance_score(y_test, lg_prediction))\n",
    "print('AdaBoostRegressor',mean_squared_error(y_test, ada_b_prediction),r2_score(y_test, ada_b_prediction), explained_variance_score(y_test, ada_b_prediction))\n",
    "print('BaggingRegressor',mean_squared_error(y_test, bagging_r_prediction),r2_score(y_test, bagging_r_prediction), explained_variance_score(y_test, bagging_r_prediction))\n",
    "print('VotingRegressor',mean_squared_error(y_test, voting_reg_prediction),r2_score(y_test, voting_reg_prediction), explained_variance_score(y_test, voting_reg_prediction))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "943cf128be303013"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
